{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.2)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/end to end projects/ATTENDENCE APP/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pip install face_recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining Google api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/photo_attendance_api_key/photo-attendance-440408-18c9a265d0b2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detects and extracts faces, then computes and saves their encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.2)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/end to end projects/ATTENDENCE APP/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from google.cloud import vision\n",
    "\n",
    "# Initialize Google Cloud Vision client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "output_file = '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/student_encodings_almost_3.json'\n",
    "\n",
    "student_photos_path = '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/all_3'\n",
    "\n",
    "\n",
    "def compute_and_save_encodings():\n",
    "    student_encodings = {}\n",
    "\n",
    "    for student_name in os.listdir(student_photos_path):\n",
    "        student_folder = os.path.join(student_photos_path, student_name)\n",
    "        if os.path.isdir(student_folder):\n",
    "            encodings = []\n",
    "            print(f\"Processing {student_name}'s photos...\")\n",
    "            for img_file in os.listdir(student_folder):\n",
    "                img_path = os.path.join(student_folder, img_file)\n",
    "\n",
    "                # agar koi folder h to skip kardo\n",
    "                if os.path.isdir(img_path):\n",
    "                    print(f\"Found directory inside {student_name}'s folder, skipping: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                # ye bounding box dedega, google api ka use karke\n",
    "                with io.open(img_path, 'rb') as image_file:\n",
    "                    content = image_file.read()\n",
    "                image = vision.Image(content=content)\n",
    "                response = client.face_detection(image=image)\n",
    "\n",
    "                if not response.face_annotations:\n",
    "                    print(f\"Can't find any face in {student_name} folder, photo: {img_file}\")\n",
    "                    continue\n",
    "\n",
    "                # bounding box ki help se face ki encodings bana rha h\n",
    "                bounds = response.face_annotations[0].bounding_poly.vertices\n",
    "                image_np = face_recognition.load_image_file(img_path)\n",
    "                top, right, bottom, left = bounds[0].y, bounds[1].x, bounds[2].y, bounds[0].x\n",
    "                face_image = image_np[top:bottom, left:right]\n",
    "                if face_image.size == 0:\n",
    "                    print(f\"Skipping {img_file} due to empty face image\")\n",
    "                    continue\n",
    "                face_encodings = face_recognition.face_encodings(face_image)\n",
    "\n",
    "                # Store the encoding\n",
    "                if face_encodings:\n",
    "                    encodings.append(face_encodings[0])\n",
    "\n",
    "            # agar multiple images use ho rhi h, to har student ke liye mean value save karenge\n",
    "            if encodings:\n",
    "                student_encodings[student_name] = np.mean(encodings, axis=0).tolist()\n",
    "\n",
    "    # encoding ki json file bana denge\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(student_encodings, f)\n",
    "\n",
    "    print(f\"Encodings saved for {len(student_encodings)} students.\")\n",
    "\n",
    "compute_and_save_encodings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loads saved encodings, computes the encoding for a classroom photo, and compares it with stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Students: ['242IT028_S.HARSHITA ', '242IT032_TARUN SAINI ', '242IT021_NANDAM SAI SAKETH', '242IT005_ABHISHEK SUNIL BHAMARE ', '242IT027_RAJESH KUMAR', '242IT017_MANISH PRAJAPATI', '242IT006_CHINMAY SATISH BHANGALE', '242IT035_YASH KACHHWAH ', '242IT036_YASHANK PATIDAR ', '242IT016_KUNDURU PHANEENDRA REDDY ', '242IT020_MITESH KUMAR MANDAL', '242IT029_SANKETHRAJ KOTAGOND ', '242IT004_ANKITA VAADIRAAJU ', '242IT011_PRAJWAL ANIL GABHANE ', '242IT015_KRATAGYA SHARMA', '242IT014_KONDURU SAI KIRAN ']\n",
      "Absent Students: ['242IT026_RAHUL NEGI ', '242IT002_AKANSH GWALWANSHI ', '242IT034_AAYUSH WAGHCHAURE ', '242IT033_TUGHUVI SWU ', '242IT018_MAYUR CHHALOTRE ', '242IT031_SURAJ BHAGAT ', '242IT003_AKASH ROHIT ', '242IT009_DIVYANSH ADURI ', '242IT010_ARYA ADWAIT DONGRE ', '242IT007_DASARI CHARAN SRINIVAS KUMAR REDDY', '243IT001_ARJUN T D', '242IT023_NOAMAAN ABDUL AZEEM ', '242IT019_MENOVI YHOSHU ', '242IT022_NISHANT SAHU', '242IT030_SHELKE AKSHAY BABASAHEB ', '242IT008_DEOBRAT KUMAR JHA ', '242IT001_ABHIJIT SAHOO ', '243IT002_PRADHAN HARSHIL KISHOR ']\n",
      "Total Students: 34\n",
      "Total Recognized Students: 16\n",
      "Total Absent Students: 18\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# input file me se encodings ko load karenge\n",
    "def load_student_encodings(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        return {name: np.array(encoding) for name, encoding in json.load(f).items()}\n",
    "\n",
    "# class photo me se faces ko extract karenge or recognize karenge\n",
    "def recognize_faces_in_single_photo(class_photo_path, student_encodings, threshold):\n",
    "\n",
    "    class_photo = face_recognition.load_image_file(class_photo_path)\n",
    "    face_locations = face_recognition.face_locations(class_photo)\n",
    "    face_encodings = face_recognition.face_encodings(class_photo, face_locations)\n",
    "\n",
    "    recognized_students = set()\n",
    "\n",
    "    for encoding in face_encodings:\n",
    "        best_match_name = None\n",
    "        lowest_distance = float('inf')  # initial case me distance infinity lelenge\n",
    "\n",
    "        # saari encodings ke saath match karenge, or best match lelenge\n",
    "        for student_name, student_encoding in student_encodings.items():\n",
    "            distance = np.linalg.norm(student_encoding - encoding)\n",
    "            \n",
    "            if distance < lowest_distance:\n",
    "                lowest_distance = distance\n",
    "                best_match_name = student_name\n",
    "\n",
    "        # agar best match threshold se kam h to usko add kardenge\n",
    "        if lowest_distance < threshold:\n",
    "            recognized_students.add(best_match_name)\n",
    "\n",
    "    return recognized_students\n",
    "\n",
    "# ......multiple photos me jo matches aa rhe h unka union lelenge(set me daal denge basically)\n",
    "def recognize_faces_in_multiple_photos(class_photo_paths, student_encodings, threshold):\n",
    "    all_recognized_students = set()\n",
    "\n",
    "    for photo_path in class_photo_paths:\n",
    "        recognized_students = recognize_faces_in_single_photo(photo_path, student_encodings, threshold)\n",
    "        all_recognized_students.update(recognized_students)\n",
    "\n",
    "    return all_recognized_students\n",
    "\n",
    "# ............... Main function jahan se encoding banane ka kaame shuru hoga\n",
    "def process_classroom_photos(class_photo_paths, input_file, threshold):\n",
    "\n",
    "    student_encodings = load_student_encodings(input_file)\n",
    "\n",
    "    recognized_students = recognize_faces_in_multiple_photos(class_photo_paths, student_encodings, threshold)\n",
    "\n",
    "    # Calculate absentees in the class\n",
    "    all_students = set(student_encodings.keys())\n",
    "    absent_students = all_students - recognized_students\n",
    "\n",
    "    print(\"Recognized Students:\", list(recognized_students))\n",
    "    print(\"Absent Students:\", list(absent_students))\n",
    "    print(\"Total Students:\", len(all_students))\n",
    "    print(\"Total Recognized Students:\", len(recognized_students))\n",
    "    print(\"Total Absent Students:\", len(absent_students))\n",
    "\n",
    "    return list(recognized_students), list(absent_students)\n",
    "\n",
    "# input_file = '/content/drive/MyDrive/photo_attendance/student_embeddings.json'\n",
    "input_file = '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/student_encodings_almost_3.json'\n",
    "\n",
    "# Dynamically provide the list of photos\n",
    "class_photo_paths = [\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/class/Jatin_kratagya_manish.jpeg',\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/class/km.jpeg',\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/class/skm_okay.jpeg'\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/akshay_rahul_mayur_deobrat_2+.jpg',\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/right_bottom.jpg'\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/center.jpg'\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/sankethraj_noamaan_ayush_abhijeet_menovi_tughuvi.jpg',\n",
    "    # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/left_bottom.jpg',\n",
    "      # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/right_top.jpg',\n",
    "      # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/right_top_2.jpg',\n",
    "      # '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost/left_top_2.jpg',\n",
    "    \n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/left_top.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/right_top.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/right_bottom.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/left_bottom.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/left_full.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/right_full.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/left_bottom.jpg',\n",
    "    #   '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/testing/almost3/full class.jpg'\n",
    "    \n",
    "]\n",
    "\n",
    "recognized_students, absent_students = process_classroom_photos(class_photo_paths, input_file, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1742.56s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/jatingrewal/Jatin/NITK/Sem 1/venv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/jatingrewal/Jatin/NITK/Sem 1/venv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance data saved to /Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/reports/attendance_report_2024-11-07_12-13-29.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "import openpyxl\n",
    "\n",
    "def create_attendance_excel(recognized_students, absent_students, output_directory):\n",
    "\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "    attendance_data = []\n",
    "\n",
    "    for student in recognized_students:\n",
    "        roll_no, name = student.split('_', 1)\n",
    "        attendance_data.append([roll_no, name.strip(), 'Present'])\n",
    "\n",
    "    for student in absent_students:\n",
    "        roll_no, name = student.split('_', 1)\n",
    "        attendance_data.append([roll_no, name.strip(), 'Absent'])\n",
    "\n",
    "    attendance_df = pd.DataFrame(attendance_data, columns=['Roll No', 'Name', 'Status'])\n",
    "\n",
    "    output_excel_file = f\"{output_directory}/attendance_report_{current_date}_{current_time}.xlsx\"\n",
    "\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "\n",
    "    sheet.merge_cells(start_row=1, start_column=1, end_row=2, end_column=3)\n",
    "    date_cell = sheet.cell(row=1, column=1)\n",
    "    date_cell.value = current_date\n",
    "    date_cell.alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "    # Write the DataFrame to the Excel sheet starting from the second row\n",
    "    for r_idx, row in enumerate(attendance_df.itertuples(index=False), start=3):\n",
    "        for c_idx, value in enumerate(row, start=1):\n",
    "            sheet.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    # Optionally, adjust column widths for better readability\n",
    "    for column in sheet.columns:\n",
    "        max_length = 0\n",
    "        column = [cell for cell in column]\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 6)\n",
    "        sheet.column_dimensions[get_column_letter(column[0].column)].width = adjusted_width\n",
    "\n",
    "    workbook.save(output_excel_file)\n",
    "\n",
    "    print(f\"Attendance data saved to {output_excel_file}\")\n",
    "\n",
    "# Define the output directory\n",
    "output_directory = '/Users/jatingrewal/Jatin/NITK/Sem 1/MIR/photo_attendance_new/reports'\n",
    "\n",
    "\n",
    "create_attendance_excel(recognized_students, absent_students, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
